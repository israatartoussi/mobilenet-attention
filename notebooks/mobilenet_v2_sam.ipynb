{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166d2a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 91/91 [01:56<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 45.8430, Accuracy: 0.7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: 34.4989, Accuracy: 0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Loss: 27.5596, Accuracy: 0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 91/91 [01:51<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Loss: 23.8451, Accuracy: 0.8894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 22.6441, Accuracy: 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Loss: 21.6018, Accuracy: 0.8970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Loss: 21.8081, Accuracy: 0.8949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Loss: 21.8746, Accuracy: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Loss: 20.3152, Accuracy: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 21.8049, Accuracy: 0.9039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 91/91 [01:51<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: 21.4542, Accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Loss: 21.2767, Accuracy: 0.9001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Loss: 20.7502, Accuracy: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Loss: 21.9367, Accuracy: 0.8959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 91/91 [01:51<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Loss: 22.5051, Accuracy: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Loss: 21.0225, Accuracy: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 91/91 [01:53<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Loss: 20.9535, Accuracy: 0.9043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 91/91 [02:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Loss: 21.2372, Accuracy: 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 91/91 [02:00<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Loss: 22.0122, Accuracy: 0.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 91/91 [01:59<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 22.0541, Accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 91/91 [01:55<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Loss: 20.5592, Accuracy: 0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 91/91 [02:01<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Loss: 21.5472, Accuracy: 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 91/91 [02:07<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Loss: 21.4640, Accuracy: 0.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 91/91 [02:07<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Loss: 22.1308, Accuracy: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 91/91 [01:54<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Loss: 20.6148, Accuracy: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Loss: 20.3878, Accuracy: 0.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Loss: 22.0997, Accuracy: 0.8918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Loss: 20.7523, Accuracy: 0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Loss: 22.0829, Accuracy: 0.8904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Loss: 20.7531, Accuracy: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 91/91 [01:51<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Loss: 21.5018, Accuracy: 0.9053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Loss: 22.0587, Accuracy: 0.9043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Loss: 20.4491, Accuracy: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Loss: 21.0183, Accuracy: 0.9070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 91/91 [01:51<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Loss: 21.2391, Accuracy: 0.9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Loss: 21.1187, Accuracy: 0.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Loss: 21.1507, Accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Loss: 23.3534, Accuracy: 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Loss: 21.9171, Accuracy: 0.8956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Loss: 21.4874, Accuracy: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Loss: 23.8974, Accuracy: 0.8966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Loss: 20.5580, Accuracy: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Loss: 21.2528, Accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Loss: 20.8531, Accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Loss: 22.3186, Accuracy: 0.8932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Loss: 20.8388, Accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Loss: 20.2506, Accuracy: 0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Loss: 21.1555, Accuracy: 0.8959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Loss: 21.4516, Accuracy: 0.8952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Loss: 21.6243, Accuracy: 0.8963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Loss: 20.9927, Accuracy: 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Loss: 20.8982, Accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Loss: 21.4537, Accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Loss: 20.9828, Accuracy: 0.8970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Loss: 21.3263, Accuracy: 0.8963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Loss: 21.8217, Accuracy: 0.8984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 91/91 [01:51<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Loss: 21.3142, Accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Loss: 20.5751, Accuracy: 0.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Loss: 22.1163, Accuracy: 0.8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Loss: 21.2963, Accuracy: 0.9074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Loss: 22.3939, Accuracy: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Loss: 21.7302, Accuracy: 0.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Loss: 23.4222, Accuracy: 0.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Loss: 21.1937, Accuracy: 0.9050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Loss: 21.1032, Accuracy: 0.9043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Loss: 21.2994, Accuracy: 0.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Loss: 22.8553, Accuracy: 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Loss: 20.9593, Accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Loss: 21.2981, Accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Loss: 21.2081, Accuracy: 0.9043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Loss: 21.1820, Accuracy: 0.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 91/91 [01:53<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Loss: 21.1428, Accuracy: 0.9025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Loss: 21.7758, Accuracy: 0.8946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 91/91 [01:54<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Loss: 22.9876, Accuracy: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Loss: 21.3104, Accuracy: 0.8980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 91/91 [01:54<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Loss: 22.4778, Accuracy: 0.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Loss: 21.5855, Accuracy: 0.8959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 91/91 [01:53<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Loss: 21.0680, Accuracy: 0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Loss: 21.2827, Accuracy: 0.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 91/91 [01:53<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Loss: 21.3279, Accuracy: 0.9036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Loss: 21.4176, Accuracy: 0.8966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Loss: 21.3890, Accuracy: 0.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Loss: 21.2981, Accuracy: 0.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 91/91 [01:53<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Loss: 20.2224, Accuracy: 0.9088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Loss: 20.6803, Accuracy: 0.9070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Loss: 20.8069, Accuracy: 0.8984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Loss: 21.9611, Accuracy: 0.9060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Loss: 20.9162, Accuracy: 0.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 91/91 [01:53<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Loss: 21.8498, Accuracy: 0.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Loss: 20.9996, Accuracy: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Loss: 21.3899, Accuracy: 0.8970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Loss: 23.6525, Accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Loss: 21.5918, Accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Loss: 20.2931, Accuracy: 0.9070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Loss: 21.6475, Accuracy: 0.8932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Loss: 21.7706, Accuracy: 0.8966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Loss: 20.9865, Accuracy: 0.9074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████| 91/91 [01:51<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Loss: 21.5031, Accuracy: 0.9036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████| 91/91 [01:52<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Loss: 21.7376, Accuracy: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 91/91 [01:52<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 21.2370, Accuracy: 0.8977\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      " Tomato___Late_blight       0.96      0.91      0.94       940\n",
      "Potato___Early_blight       0.85      0.93      0.89       494\n",
      "\n",
      "             accuracy                           0.92      1434\n",
      "            macro avg       0.90      0.92      0.91      1434\n",
      "         weighted avg       0.92      0.92      0.92      1434\n",
      "\n",
      "F1 Score: 0.9185 | Precision: 0.9215 | Recall: 0.9177\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (320,1,1) (3,224,224) ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 220\u001b[39m\n\u001b[32m    217\u001b[39m     plt.title(\u001b[33m\"\u001b[39m\u001b[33mGrad-CAM SAM\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    218\u001b[39m     plt.savefig(\u001b[33m\"\u001b[39m\u001b[33mgradcam_sam_layer.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[43mapply_gradcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# t-SNE Visualization\u001b[39;00m\n\u001b[32m    223\u001b[39m all_features = torch.cat(all_features, dim=\u001b[32m0\u001b[39m).numpy()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 206\u001b[39m, in \u001b[36mapply_gradcam\u001b[39m\u001b[34m(model, input_tensor)\u001b[39m\n\u001b[32m    204\u001b[39m activation = target_layer(input_tensor).detach()[\u001b[32m0\u001b[39m].cpu().numpy()\n\u001b[32m    205\u001b[39m weights = np.mean(gradient, axis=(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m cam = np.sum(\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    207\u001b[39m cam = np.maximum(cam, \u001b[32m0\u001b[39m)\n\u001b[32m    208\u001b[39m cam = cam / cam.max()\n",
      "\u001b[31mValueError\u001b[39m: operands could not be broadcast together with shapes (320,1,1) (3,224,224) "
     ]
    }
   ],
   "source": [
    "\n",
    "# Required imports\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models.mobilenetv2 import InvertedResidual\n",
    "from torchvision.models import MobileNet_V2_Weights\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # non-GUI backend\n",
    "\n",
    "# Import SAM\n",
    "sys.path.append('../models')\n",
    "from sam import SAM\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transforms\n",
    "weights = MobileNet_V2_Weights.DEFAULT\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    weights.transforms()\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    weights.transforms()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "full_train_dataset = datasets.ImageFolder('../../dataset_split/train', transform=train_transforms)\n",
    "full_val_dataset = datasets.ImageFolder('../../dataset_split/val', transform=val_transforms)\n",
    "\n",
    "# Select classes\n",
    "selected_classes = ['Tomato___Late_blight', 'Potato___Early_blight']\n",
    "selected_class_indices = [full_train_dataset.class_to_idx[cls] for cls in selected_classes]\n",
    "index_mapping = {orig_idx: new_idx for new_idx, orig_idx in enumerate(selected_class_indices)}\n",
    "\n",
    "class ReindexedSubset(Dataset):\n",
    "    def __init__(self, subset, class_indices_mapping):\n",
    "        self.subset = subset\n",
    "        self.mapping = class_indices_mapping\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        y = self.mapping[y]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "def filter_and_remap(dataset, class_indices, mapping):\n",
    "    indices = [i for i, (_, label) in enumerate(dataset) if label in class_indices]\n",
    "    subset = Subset(dataset, indices)\n",
    "    return ReindexedSubset(subset, mapping)\n",
    "\n",
    "train_dataset = filter_and_remap(full_train_dataset, selected_class_indices, index_mapping)\n",
    "val_dataset = filter_and_remap(full_val_dataset, selected_class_indices, index_mapping)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "class MobileNetV2_SAM(nn.Module):\n",
    "    def __init__(self, base_model, num_classes):\n",
    "        super(MobileNetV2_SAM, self).__init__()\n",
    "        self.features = nn.Sequential()\n",
    "        for name, module in base_model.features._modules.items():\n",
    "            self.features.add_module(name, module)\n",
    "            if isinstance(module, InvertedResidual):\n",
    "                conv_layers = [layer for layer in module.conv if isinstance(layer, nn.Conv2d)]\n",
    "                out_channels = conv_layers[-1].out_channels if conv_layers else base_model.last_channel\n",
    "                self.features.add_module(f\"sam_{name}\", SAM(out_channels))\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(base_model.last_channel, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "base_model = models.mobilenet_v2(weights=weights)\n",
    "model = MobileNetV2_SAM(base_model, len(selected_classes)).to(device)\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "# Train\n",
    "NUM_EPOCHS = 100\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    acc = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {running_loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"mobilenet_v2_sam.pth\")\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "all_labels, all_preds, all_features = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        features = model.features(images).mean(dim=[2, 3])  # global avg pool features\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_features.append(features.cpu())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Reports\n",
    "print(classification_report(all_labels, all_preds, target_names=selected_classes))\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", xticklabels=selected_classes, yticklabels=selected_classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"confMatrix_sam.png\")\n",
    "\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "print(f\"F1 Score: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n",
    "\n",
    "# Single image prediction example\n",
    "images, labels = next(iter(val_loader))\n",
    "input_tensor = images[0].unsqueeze(0).to(device)\n",
    "true_label = labels[0].item()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    pred_label = predicted.item()\n",
    "\n",
    "image_np = images[0].permute(1, 2, 0).cpu().numpy()\n",
    "image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "image_np = np.clip(image_np, 0, 1)\n",
    "plt.imshow(image_np)\n",
    "plt.title(f\"True: {selected_classes[true_label]} | Predicted: {selected_classes[pred_label]}\")\n",
    "plt.axis('off')\n",
    "plt.savefig(\"test_output_sam.png\")\n",
    "\n",
    "# Grad-CAM (simplified version)\n",
    "def apply_gradcam(model, input_tensor):\n",
    "    model.eval()\n",
    "    gradients = []\n",
    "\n",
    "    def save_gradient(grad):\n",
    "        gradients.append(grad)\n",
    "\n",
    "    # Choose last SAM layer\n",
    "    for name, module in reversed(list(model.features.named_children())):\n",
    "        if 'sam' in name:\n",
    "            target_layer = module\n",
    "            break\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        output.register_hook(save_gradient)\n",
    "        return output\n",
    "\n",
    "    handle = target_layer.register_forward_hook(forward_hook)\n",
    "    output = model(input_tensor)\n",
    "    pred_class = output.argmax().item()\n",
    "    model.zero_grad()\n",
    "    class_loss = output[0, pred_class]\n",
    "    class_loss.backward()\n",
    "    handle.remove()\n",
    "\n",
    "    gradient = gradients[0][0].cpu().numpy()\n",
    "    activation = target_layer(input_tensor).detach()[0].cpu().numpy()\n",
    "    weights = np.mean(gradient, axis=(1, 2))\n",
    "    cam = np.sum(weights[:, None, None] * activation, axis=0)\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / cam.max()\n",
    "    cam = plt.cm.jet(cam)[..., :3]\n",
    "\n",
    "    orig_image = input_tensor[0].cpu().permute(1, 2, 0).numpy()\n",
    "    orig_image = orig_image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    orig_image = np.clip(orig_image, 0, 1)\n",
    "    overlay = 0.5 * cam + 0.5 * orig_image\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Grad-CAM SAM\")\n",
    "    plt.savefig(\"gradcam_sam_layer.png\")\n",
    "\n",
    "apply_gradcam(model, input_tensor)\n",
    "\n",
    "# t-SNE Visualization\n",
    "all_features = torch.cat(all_features, dim=0).numpy()\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=3000, random_state=42)\n",
    "features_2d = tsne.fit_transform(all_features)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, label in enumerate(np.unique(all_labels)):\n",
    "    indices = np.where(np.array(all_labels) == label)\n",
    "    plt.scatter(features_2d[indices, 0], features_2d[indices, 1], label=selected_classes[label], alpha=0.6)\n",
    "plt.legend()\n",
    "plt.title(\"t-SNE Visualization SAM\")\n",
    "plt.savefig(\"tsne_plot_sam.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2c00f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7352c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def apply_gradcam(model, input_tensor, target_layer_name=\"sam_17\"):\n",
    "    activations = []\n",
    "    gradients = []\n",
    "\n",
    "    try:\n",
    "        # اختيار الطبقة المستهدفة\n",
    "        target_layer = model.features._modules[target_layer_name]\n",
    "    except KeyError:\n",
    "        print(f\"[ERROR] Layer '{target_layer_name}' not found in model.features.\")\n",
    "        print(\"Available layers:\")\n",
    "        for name in model.features._modules.keys():\n",
    "            print(\"-\", name)\n",
    "        return\n",
    "\n",
    "    # Hooks\n",
    "    def forward_hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    def backward_hook(module, grad_input, grad_output):\n",
    "        gradients.append(grad_output[0])\n",
    "\n",
    "    # Register hooks\n",
    "    forward_handle = target_layer.register_forward_hook(forward_hook)\n",
    "    backward_handle = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    # Forward and backward\n",
    "    model.eval()\n",
    "    output = model(input_tensor)\n",
    "    class_idx = output.argmax().item()\n",
    "    print(\"[INFO] Predicted class index:\", class_idx)\n",
    "    loss = output[0, class_idx]\n",
    "    loss.backward()\n",
    "\n",
    "    # Remove hooks\n",
    "    forward_handle.remove()\n",
    "    backward_handle.remove()\n",
    "\n",
    "    if not activations or not gradients:\n",
    "        print(\"[ERROR] Activations or gradients are empty.\")\n",
    "        return\n",
    "\n",
    "    act = activations[0].detach().cpu().squeeze(0).numpy()  # (C, H, W)\n",
    "    grad = gradients[0].detach().cpu().squeeze(0).numpy()   # (C, H, W)\n",
    "\n",
    "    print(\"Activation shape:\", act.shape)\n",
    "    print(\"Gradient shape:\", grad.shape)\n",
    "\n",
    "    # Compute weights and CAM\n",
    "    weights = np.mean(grad, axis=(1, 2))                    # (C,)\n",
    "    cam = np.sum(weights[:, None, None] * act, axis=0)\n",
    "\n",
    "    if np.isnan(cam).any() or np.max(cam) == 0:\n",
    "        print(\"[ERROR] CAM contains NaNs or all values are zero.\")\n",
    "        return\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / np.max(cam)\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "\n",
    "    # Visualization\n",
    "    plt.imshow(cam, cmap=\"jet\", alpha=0.5)\n",
    "    plt.title(f\"Grad-CAM {target_layer_name}\")\n",
    "    save_path = f\"gradcam_{target_layer_name}.png\"\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"[SUCCESS] Saved Grad-CAM to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a0f93e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itartoussi/miniconda3/envs/agml_env_312/lib/python3.12/site-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicted class index: 1\n",
      "Activation shape: (320, 7, 7)\n",
      "Gradient shape: (320, 7, 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] Saved Grad-CAM to gradcam_sam_17.png\n"
     ]
    }
   ],
   "source": [
    "apply_gradcam(model, input_tensor, target_layer_name=\"sam_17\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49ad03a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MobileNetV2_SAM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m base_model = models.mobilenet_v2(weights=\u001b[33m\"\u001b[39m\u001b[33mDEFAULT\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m model = \u001b[43mMobileNetV2_SAM\u001b[49m(base_model, num_classes=num_classes).to(device)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_features_tsne\u001b[39m(model, dataloader, device):\n\u001b[32m     17\u001b[39m     model.eval()\n",
      "\u001b[31mNameError\u001b[39m: name 'MobileNetV2_SAM' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "selected_classes = ['Tomato___Late_blight', 'Potato___Early_blight']\n",
    "num_classes = len(selected_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_model = models.mobilenet_v2(weights=\"DEFAULT\")\n",
    "model = MobileNetV2_SAM(base_model, num_classes=num_classes).to(device)\n",
    "\n",
    "def extract_features_tsne(model, dataloader, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model.features(inputs)\n",
    "            pooled = nn.AdaptiveAvgPool2d((1, 1))(outputs)\n",
    "            pooled = pooled.view(pooled.size(0), -1)\n",
    "            features.append(pooled.cpu())\n",
    "            labels.append(targets)\n",
    "    features = torch.cat(features, dim=0).numpy()\n",
    "    labels = torch.cat(labels, dim=0).numpy()\n",
    "    return features, labels\n",
    "\n",
    "def plot_tsne(features, labels, class_names):\n",
    "    tsne = TSNE(n_components=2, perplexity=30, n_iter=3000, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(features)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1],\n",
    "                    hue=[class_names[label] for label in labels],\n",
    "                    palette=\"deep\", s=60, alpha=0.7)\n",
    "    plt.title(\"t-SNE Visualization of SAM Features\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"tsne_sam.png\")\n",
    "    plt.show()\n",
    "\n",
    "features, labels = extract_features_tsne(model, test_loader, device)\n",
    "plot_tsne(features, labels, selected_classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agml_env_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
